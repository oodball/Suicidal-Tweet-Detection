{"cells":[{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pandas in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.1)\n","Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.26.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\audre\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.1)\n","Requirement already satisfied: six>=1.5 in c:\\users\\audre\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: numpy in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.26.2)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: nltk in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.1)\n","Requirement already satisfied: click in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2023.12.25)\n","Requirement already satisfied: tqdm in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.66.2)\n","Requirement already satisfied: colorama in c:\\users\\audre\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.6)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: scikit-learn in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.1.post1)\n","Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.26.2)\n","Requirement already satisfied: scipy>=1.6.0 in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.12.0)\n","Requirement already satisfied: joblib>=1.2.0 in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.3.0)\n","Note: you may need to restart the kernel to use updated packages.\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: Could not find a version that satisfies the requirement re (from versions: none)\n","ERROR: No matching distribution found for re\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: matplotlib in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.3)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.49.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.26.2)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\audre\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (23.2)\n","Requirement already satisfied: pillow>=8 in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (10.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\audre\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\audre\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in c:\\users\\audre\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install pandas\n","%pip install numpy\n","%pip install nltk\n","%pip install scikit-learn\n","%pip install re\n","%pip install matplotlib"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4290,"status":"ok","timestamp":1709180290489,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"PB2Xw0plsSHJ","outputId":"5112f47e-ce1a-4db6-c369-cc3b6326a5d1"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\audre\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\audre\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     C:\\Users\\audre\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\audre\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('wordnet')\n","from nltk.corpus import stopwords\n","stop_words = stopwords.words('english')\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import wordnet\n","\n","# notebook configurations\n","pd.options.display.max_colwidth = 1000\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1709180290492,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"LsrO3RdWsTe1"},"outputs":[],"source":["df = pd.read_csv(\"suicide.csv\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":476},"executionInfo":{"elapsed":659,"status":"ok","timestamp":1709180291139,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"s2suf6masiAb","outputId":"2fb9af4a-e8ab-473b-f3f7-fa37c51afc10"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweet</th>\n","      <th>Suicide</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>make lunch</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>alexia want money</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>dizzyhrvy crap take forever put together go go sleep day</td>\n","      <td>Potential Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>jnaylor kiwitweets hey jer since start twittering</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>try quot delicious library quot mixed result bar code think want add sport bra instead drill cool app tho</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1782</th>\n","      <td>forgotten much love nokia</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>1783</th>\n","      <td>start day positive attitude great watch greatness</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>1784</th>\n","      <td>hey give girl credit try</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>1785</th>\n","      <td>drunken besties stumble room run around sober cj drunk hope knock door good time</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>1786</th>\n","      <td>dancingbonita quot friggin love quot ron burgundy rid unicorn</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1787 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                                                                          Tweet  \\\n","0                                                                                                    make lunch   \n","1                                                                                             alexia want money   \n","2                                                      dizzyhrvy crap take forever put together go go sleep day   \n","3                                                             jnaylor kiwitweets hey jer since start twittering   \n","4     try quot delicious library quot mixed result bar code think want add sport bra instead drill cool app tho   \n","...                                                                                                         ...   \n","1782                                                                                  forgotten much love nokia   \n","1783                                                          start day positive attitude great watch greatness   \n","1784                                                                                   hey give girl credit try   \n","1785                           drunken besties stumble room run around sober cj drunk hope knock door good time   \n","1786                                              dancingbonita quot friggin love quot ron burgundy rid unicorn   \n","\n","                      Suicide  \n","0            Not Suicide post  \n","1            Not Suicide post  \n","2     Potential Suicide post   \n","3            Not Suicide post  \n","4            Not Suicide post  \n","...                       ...  \n","1782         Not Suicide post  \n","1783         Not Suicide post  \n","1784         Not Suicide post  \n","1785         Not Suicide post  \n","1786         Not Suicide post  \n","\n","[1787 rows x 2 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1709180291139,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"mgZDwboDuEBF","outputId":"e5faeaed-5fc5-4201-ed3e-2b28371bd448"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweet</th>\n","      <th>Suicide</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>make lunch</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>alexia want money</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>dizzyhrvy crap take forever put together go go sleep day</td>\n","      <td>Potential Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>jnaylor kiwitweets hey jer since start twittering</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>try quot delicious library quot mixed result bar code think want add sport bra instead drill cool app tho</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                       Tweet  \\\n","0                                                                                                 make lunch   \n","1                                                                                          alexia want money   \n","2                                                   dizzyhrvy crap take forever put together go go sleep day   \n","3                                                          jnaylor kiwitweets hey jer since start twittering   \n","4  try quot delicious library quot mixed result bar code think want add sport bra instead drill cool app tho   \n","\n","                   Suicide  \n","0         Not Suicide post  \n","1         Not Suicide post  \n","2  Potential Suicide post   \n","3         Not Suicide post  \n","4         Not Suicide post  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df.head(5)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1709180291139,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"5PNUZlDY6JjM","outputId":"533b365e-dbed-4db3-dd29-665005b5116d"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1787 entries, 0 to 1786\n","Data columns (total 2 columns):\n"," #   Column   Non-Null Count  Dtype \n","---  ------   --------------  ----- \n"," 0   Tweet    1785 non-null   object\n"," 1   Suicide  1787 non-null   object\n","dtypes: object(2)\n","memory usage: 28.0+ KB\n"]}],"source":["df.info()"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocessing Data"]},{"cell_type":"markdown","metadata":{"id":"j42_h2ZWAUKP"},"source":["## Drop empty rows\n","\n","In our case the rows without a Tweet entry do not have a significant meaning, hence we may drop them."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1709180291140,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"ZHCmg-nvAjpf","outputId":"027ff81e-fa36-4adb-ab0a-0361cb40f5ef"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweet</th>\n","      <th>Suicide</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>497</th>\n","      <td>NaN</td>\n","      <td>Potential Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>1017</th>\n","      <td>NaN</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Tweet                  Suicide\n","497    NaN  Potential Suicide post \n","1017   NaN         Not Suicide post"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df[df[\"Tweet\"].isnull()]"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":476},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1709180291140,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"W8lfkj57Afyr","outputId":"4464b0d3-5605-4aae-e1d4-aa19f5256a04"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweet</th>\n","      <th>Suicide</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>make lunch</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>alexia want money</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>dizzyhrvy crap take forever put together go go sleep day</td>\n","      <td>Potential Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>jnaylor kiwitweets hey jer since start twittering</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>try quot delicious library quot mixed result bar code think want add sport bra instead drill cool app tho</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1782</th>\n","      <td>forgotten much love nokia</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>1783</th>\n","      <td>start day positive attitude great watch greatness</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>1784</th>\n","      <td>hey give girl credit try</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>1785</th>\n","      <td>drunken besties stumble room run around sober cj drunk hope knock door good time</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>1786</th>\n","      <td>dancingbonita quot friggin love quot ron burgundy rid unicorn</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1785 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                                                                          Tweet  \\\n","0                                                                                                    make lunch   \n","1                                                                                             alexia want money   \n","2                                                      dizzyhrvy crap take forever put together go go sleep day   \n","3                                                             jnaylor kiwitweets hey jer since start twittering   \n","4     try quot delicious library quot mixed result bar code think want add sport bra instead drill cool app tho   \n","...                                                                                                         ...   \n","1782                                                                                  forgotten much love nokia   \n","1783                                                          start day positive attitude great watch greatness   \n","1784                                                                                   hey give girl credit try   \n","1785                           drunken besties stumble room run around sober cj drunk hope knock door good time   \n","1786                                              dancingbonita quot friggin love quot ron burgundy rid unicorn   \n","\n","                      Suicide  \n","0            Not Suicide post  \n","1            Not Suicide post  \n","2     Potential Suicide post   \n","3            Not Suicide post  \n","4            Not Suicide post  \n","...                       ...  \n","1782         Not Suicide post  \n","1783         Not Suicide post  \n","1784         Not Suicide post  \n","1785         Not Suicide post  \n","1786         Not Suicide post  \n","\n","[1785 rows x 2 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df.dropna()"]},{"cell_type":"markdown","metadata":{"id":"EIXp1HkP7NO3"},"source":["### Remove punctuation\n","\n","Removing punctuation in data cleaning is important for noise reduction, text standardization, tokenization, and improving language syntax. Punctuation marks usually do not carry significant meaning on their own and can introduce unnecessary noise in the text data. By removing punctuation, the text is standardized, making it easier for the model to process and analyze. Additionally, punctuation marks are typically treated as separate tokens during tokenization, and removing them helps create cleaner and more meaningful tokens."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":476},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1709180291140,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"LRpyg6Kp64Js","outputId":"9697e87d-0c26-4e64-fdfe-00aa70550fe0"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweet</th>\n","      <th>Suicide</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>make lunch</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>alexia want money</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>dizzyhrvy crap take forever put together go go sleep day</td>\n","      <td>Potential Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>jnaylor kiwitweets hey jer since start twittering</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>try quot delicious library quot mixed result bar code think want add sport bra instead drill cool app tho</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1782</th>\n","      <td>forgotten much love nokia</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>1783</th>\n","      <td>start day positive attitude great watch greatness</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>1784</th>\n","      <td>hey give girl credit try</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>1785</th>\n","      <td>drunken besties stumble room run around sober cj drunk hope knock door good time</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","    <tr>\n","      <th>1786</th>\n","      <td>dancingbonita quot friggin love quot ron burgundy rid unicorn</td>\n","      <td>Not Suicide post</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1787 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                                                                          Tweet  \\\n","0                                                                                                    make lunch   \n","1                                                                                             alexia want money   \n","2                                                      dizzyhrvy crap take forever put together go go sleep day   \n","3                                                             jnaylor kiwitweets hey jer since start twittering   \n","4     try quot delicious library quot mixed result bar code think want add sport bra instead drill cool app tho   \n","...                                                                                                         ...   \n","1782                                                                                  forgotten much love nokia   \n","1783                                                          start day positive attitude great watch greatness   \n","1784                                                                                   hey give girl credit try   \n","1785                           drunken besties stumble room run around sober cj drunk hope knock door good time   \n","1786                                              dancingbonita quot friggin love quot ron burgundy rid unicorn   \n","\n","                      Suicide  \n","0            Not Suicide post  \n","1            Not Suicide post  \n","2     Potential Suicide post   \n","3            Not Suicide post  \n","4            Not Suicide post  \n","...                       ...  \n","1782         Not Suicide post  \n","1783         Not Suicide post  \n","1784         Not Suicide post  \n","1785         Not Suicide post  \n","1786         Not Suicide post  \n","\n","[1787 rows x 2 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df[\"Tweet\"] = df[\"Tweet\"].apply(lambda x: re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", str(x)))\n","df"]},{"cell_type":"markdown","metadata":{"id":"umVaXxBE8sAx"},"source":["### Remove words with number\n","\n","Removing words with numbers during data cleaning of product names eliminates numerical information that may not be relevant for the task at hand. Numerical values in product names often represent specific attributes, such as sizes or model numbers, which may not contribute to product understanding or classification. By removing these words, we focus on descriptive and discriminative features, simplifying the text representation for accurate predictions.\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":341,"status":"ok","timestamp":1709180291452,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"AYCTfpaj8tNz"},"outputs":[],"source":["df[\"Tweet\"] = df[\"Tweet\"].apply(lambda x: ' '.join([word for word in x.split() if not re.search(r'\\d', word)]))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1709180291452,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"IRceFBmD85Ql","outputId":"c25b0861-b135-4ab2-a37d-423067db2c6c"},"outputs":[{"data":{"text/plain":["0                                                                                                   make lunch\n","1                                                                                            alexia want money\n","2                                                     dizzyhrvy crap take forever put together go go sleep day\n","3                                                            jnaylor kiwitweets hey jer since start twittering\n","4    try quot delicious library quot mixed result bar code think want add sport bra instead drill cool app tho\n","Name: Tweet, dtype: object"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df[\"Tweet\"].head()"]},{"cell_type":"markdown","metadata":{"id":"Ghgr3sP293PV"},"source":["### Remove single string characters\n","\n","Removing single-character strings during data cleaning is important as they often do not provide meaningful information and can introduce noise. By removing them, we can improve the quality of the text data and focus on more relevant words. This helps to reduce dimensionality, eliminate unnecessary noise, and improve the efficiency of subsequent text analysis tasks."]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1709180291453,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"zh1zK7bd940x"},"outputs":[],"source":["df[\"Tweet\"] = df[\"Tweet\"].str.replace(r'\\b\\w\\b', \"\", regex = True)"]},{"cell_type":"markdown","metadata":{"id":"1ccda5d4"},"source":["### Lowercase\n","\n","Lowercasing text during data cleaning in our project is important for standardization and consistency. It treats words with different cases as the same, reducing the vocabulary size and improving performance in subsequent tasks. Lowercasing ensures that words like ```Hello``` and ```hello``` are represented uniformly, making it easier to compare and analyze the text data."]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1709180291453,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"pRVy-FwH-nqf"},"outputs":[],"source":["df[\"Tweet\"] = df[\"Tweet\"].str.lower()"]},{"cell_type":"markdown","metadata":{"id":"0f785652"},"source":["### Remove stop words\n","\n","Stop words are commonly used words such as \"a,\" \"the,\" \"is,\" which do not carry significant meaning and can introduce noise to the analysis. By removing stop words, we can reduce the dimensionality of the data and focus on more informative and content-rich words."]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1709180291453,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"Sa45KG0Y-y5p"},"outputs":[],"source":["def remove_stop_words(input_string):\n","    # Tokenize the string\n","    tokens = word_tokenize(input_string)\n","\n","    # Get the list of English stop words\n","    stop_words = set(stopwords.words(\"english\"))\n","\n","    # Remove stop words\n","    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n","\n","    # Reconstruct the string\n","    output_string = \" \".join(filtered_tokens)\n","\n","    return output_string"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":1129,"status":"ok","timestamp":1709180292577,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"sgZ7I-jB-00k"},"outputs":[],"source":["# Apply to column \"name\"\n","df[\"Tweet\"] = df[\"Tweet\"].apply(remove_stop_words)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1709180292577,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"mubkIeBo-5ue","outputId":"a75c9219-6139-4571-df05-263de8ab3138"},"outputs":[{"data":{"text/plain":["0                                                                                                      make lunch\n","1                                                                                               alexia want money\n","2                                                        dizzyhrvy crap take forever put together go go sleep day\n","3                                                               jnaylor kiwitweets hey jer since start twittering\n","4       try quot delicious library quot mixed result bar code think want add sport bra instead drill cool app tho\n","                                                          ...                                                    \n","1782                                                                                    forgotten much love nokia\n","1783                                                            start day positive attitude great watch greatness\n","1784                                                                                     hey give girl credit try\n","1785                             drunken besties stumble room run around sober cj drunk hope knock door good time\n","1786                                                dancingbonita quot friggin love quot ron burgundy rid unicorn\n","Name: Tweet, Length: 1787, dtype: object"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["df.Tweet"]},{"cell_type":"markdown","metadata":{"id":"Sh_1F-ZO_ljb"},"source":["### Part-of-Speech (POS) Tagging and Lemmatize the words\n","\n","POS tagging identifies the grammatical category of each word, while lemmatization reduces words to their base form. By using POS tags, we accurately lemmatize words, ensuring consistent representation across different grammatical forms."]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1709180292577,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"Rtx7IkAp-81g"},"outputs":[],"source":["def get_wordnet_pos(tag):\n","    if tag.startswith(\"N\"):\n","        return wordnet.NOUN\n","    elif tag.startswith(\"V\"):\n","        return wordnet.VERB\n","    elif tag.startswith(\"J\"):\n","        return wordnet.ADV\n","    else:\n","        return wordnet.NOUN"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3860,"status":"ok","timestamp":1709180296433,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"50cilJ6-_roy","outputId":"9cf067f1-2b58-4bf8-bacd-e8760627e5e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["kids (NNS) --> kid (n)\n","smart (VBP) --> smart (v)\n","watch (NN) --> watch (n)\n","for (IN) --> for (n)\n","girls (NNS) --> girl (n)\n","toy (NN) --> toy (n)\n","for (IN) --> for (n)\n","kids (NNS) --> kid (n)\n","gift (NN) --> gift (n)\n","for (IN) --> for (n)\n","girls (NNS) --> girl (n)\n","watches (NNS) --> watch (n)\n"]}],"source":["lemmatizer = WordNetLemmatizer()\n","sent = \"kids smart watch for girls toy for kids gift for girls watches\"\n","\n","tagged_words = nltk.pos_tag(word_tokenize(sent))\n","for word, w_tag in tagged_words:\n","    lemma_tag = get_wordnet_pos(w_tag)\n","    lemma = lemmatizer.lemmatize(word, lemma_tag)\n","    print(f\"{word} ({w_tag}) --> {lemma} ({lemma_tag})\")"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":5571,"status":"ok","timestamp":1709180301971,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"Jbhhfjjm_tGv"},"outputs":[],"source":["df[\"Tweet\"] = df[\"Tweet\"].apply(lambda x: \" \".join([lemmatizer.lemmatize(word, pos = get_wordnet_pos(w_tag)) for word, w_tag in nltk.pos_tag(word_tokenize(x))]))"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1709180301972,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"gGhDofWg_-fI"},"outputs":[],"source":["df_cleaned = df\n","df_cleaned.to_csv(\"suicide.csv\", index = False)"]},{"cell_type":"markdown","metadata":{},"source":["## Run VADER"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1709180301973,"user":{"displayName":"Amara Sharma","userId":"12262905783054412520"},"user_tz":480},"id":"bWlIKAfBBZa8"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package vader_lexicon to\n","[nltk_data]     C:\\Users\\audre\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n"]}],"source":["import nltk\n","nltk.download('vader_lexicon')\n","\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","from sklearn.decomposition import PCA\n","\n","vader = SentimentIntensityAnalyzer()"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweet</th>\n","      <th>sentiment_scores</th>\n","      <th>compound_scores</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>make lunch</td>\n","      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>alexia want money</td>\n","      <td>{'neg': 0.0, 'neu': 0.606, 'pos': 0.394, 'compound': 0.0772}</td>\n","      <td>0.0772</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>dizzyhrvy crap take forever put together go go sleep day</td>\n","      <td>{'neg': 0.224, 'neu': 0.776, 'pos': 0.0, 'compound': -0.3818}</td>\n","      <td>-0.3818</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>jnaylor kiwitweets hey jer since start twittering</td>\n","      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>try quot delicious library quot mixed result bar code think want add sport bra instead drill cool app tho</td>\n","      <td>{'neg': 0.0, 'neu': 0.687, 'pos': 0.313, 'compound': 0.743}</td>\n","      <td>0.7430</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1782</th>\n","      <td>forgotten much love nokia</td>\n","      <td>{'neg': 0.235, 'neu': 0.247, 'pos': 0.519, 'compound': 0.5106}</td>\n","      <td>0.5106</td>\n","    </tr>\n","    <tr>\n","      <th>1783</th>\n","      <td>start day positive attitude great watch greatness</td>\n","      <td>{'neg': 0.0, 'neu': 0.394, 'pos': 0.606, 'compound': 0.8271}</td>\n","      <td>0.8271</td>\n","    </tr>\n","    <tr>\n","      <th>1784</th>\n","      <td>hey give girl credit try</td>\n","      <td>{'neg': 0.0, 'neu': 0.606, 'pos': 0.394, 'compound': 0.3818}</td>\n","      <td>0.3818</td>\n","    </tr>\n","    <tr>\n","      <th>1785</th>\n","      <td>drunken besties stumble room run around sober cj drunk hope knock door good time</td>\n","      <td>{'neg': 0.125, 'neu': 0.573, 'pos': 0.302, 'compound': 0.5267}</td>\n","      <td>0.5267</td>\n","    </tr>\n","    <tr>\n","      <th>1786</th>\n","      <td>dancingbonita quot friggin love quot ron burgundy rid unicorn</td>\n","      <td>{'neg': 0.0, 'neu': 0.64, 'pos': 0.36, 'compound': 0.6697}</td>\n","      <td>0.6697</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1787 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                                                                          Tweet  \\\n","0                                                                                                    make lunch   \n","1                                                                                             alexia want money   \n","2                                                      dizzyhrvy crap take forever put together go go sleep day   \n","3                                                             jnaylor kiwitweets hey jer since start twittering   \n","4     try quot delicious library quot mixed result bar code think want add sport bra instead drill cool app tho   \n","...                                                                                                         ...   \n","1782                                                                                  forgotten much love nokia   \n","1783                                                          start day positive attitude great watch greatness   \n","1784                                                                                   hey give girl credit try   \n","1785                           drunken besties stumble room run around sober cj drunk hope knock door good time   \n","1786                                              dancingbonita quot friggin love quot ron burgundy rid unicorn   \n","\n","                                                    sentiment_scores  \\\n","0              {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}   \n","1       {'neg': 0.0, 'neu': 0.606, 'pos': 0.394, 'compound': 0.0772}   \n","2      {'neg': 0.224, 'neu': 0.776, 'pos': 0.0, 'compound': -0.3818}   \n","3              {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}   \n","4        {'neg': 0.0, 'neu': 0.687, 'pos': 0.313, 'compound': 0.743}   \n","...                                                              ...   \n","1782  {'neg': 0.235, 'neu': 0.247, 'pos': 0.519, 'compound': 0.5106}   \n","1783    {'neg': 0.0, 'neu': 0.394, 'pos': 0.606, 'compound': 0.8271}   \n","1784    {'neg': 0.0, 'neu': 0.606, 'pos': 0.394, 'compound': 0.3818}   \n","1785  {'neg': 0.125, 'neu': 0.573, 'pos': 0.302, 'compound': 0.5267}   \n","1786      {'neg': 0.0, 'neu': 0.64, 'pos': 0.36, 'compound': 0.6697}   \n","\n","      compound_scores  \n","0              0.0000  \n","1              0.0772  \n","2             -0.3818  \n","3              0.0000  \n","4              0.7430  \n","...               ...  \n","1782           0.5106  \n","1783           0.8271  \n","1784           0.3818  \n","1785           0.5267  \n","1786           0.6697  \n","\n","[1787 rows x 3 columns]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["def sentiment_scores(text):\n","    return vader.polarity_scores(text)\n","\n","\n","df_cleaned['sentiment_scores'] = df_cleaned['Tweet'].apply(sentiment_scores)\n","df_cleaned['compound_scores'] = df_cleaned['sentiment_scores'].apply(lambda x: x['compound'])\n","\n","df_cleaned.to_csv('sentiment_scores.csv', index=False)\n","\n","scores = pd.read_csv(\"sentiment_scores.csv\").drop('Suicide', axis = 1)\n","\n","scores"]},{"cell_type":"markdown","metadata":{},"source":["## Run PCA"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'Series' object has no attribute 'reshape'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10440\\2146029097.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mrisk_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_cleaned\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'compound_scores'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcompound_scores_reshaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrisk_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\audre\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6293\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6294\u001b[0m         ):\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6296\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'reshape'"]}],"source":["from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","import numpy as np\n","\n","\n","risk_data = df_cleaned['compound_scores'].reshape(-1, 1)\n","\n","\n","compound_scores_reshaped = risk_data.values\n","\n","#standardization\n","scaler = StandardScaler()\n","compound_scores_scaled = scaler.fit_transform(compound_scores_reshaped)\n","\n","pca = PCA(n_components=2)  \n","pca_scores = pca.fit_transform(risk_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
